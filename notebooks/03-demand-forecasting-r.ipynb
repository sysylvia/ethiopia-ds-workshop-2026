{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Demand Forecasting with Machine Learning (R Version)\n",
    "\n",
    "**WISE Workshop | Addis Ababa, Feb 2026**\n",
    "\n",
    "In this notebook, you'll build your first machine learning models to forecast demand in the pharmaceutical supply chain using tidymodels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "::: {.callout-important}\n",
    "## Google Colab R Runtime\n",
    "Make sure you're using the R runtime: **Runtime -> Change runtime type -> R**\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if needed (run once in Colab)\n",
    "if (!require(\"tidymodels\", quietly = TRUE)) {\n",
    "  install.packages(c(\"tidymodels\", \"ranger\", \"xgboost\", \"vip\"))\n",
    "}\n",
    "\n",
    "# Load packages\n",
    "library(tidymodels)\n",
    "library(tidyverse)\n",
    "library(vip)  # For variable importance plots\n",
    "\n",
    "# Settings\n",
    "set.seed(42)\n",
    "theme_set(theme_minimal())\n",
    "\n",
    "cat(\"Packages loaded!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data (will be replaced with real data URL)\n",
    "set.seed(42)\n",
    "n_rows <- 1000\n",
    "\n",
    "# Generate data with patterns\n",
    "dates <- seq(as.Date('2023-01-01'), by = 'day', length.out = n_rows)\n",
    "regions <- sample(c('Addis Ababa', 'Oromia', 'Amhara', 'SNNP', 'Tigray'), n_rows, replace = TRUE)\n",
    "facility_types <- sample(c('Hospital', 'Health Center', 'Clinic'), n_rows, replace = TRUE, \n",
    "                        prob = c(0.2, 0.5, 0.3))\n",
    "\n",
    "# Create demand with seasonal pattern and facility effects\n",
    "base_demand <- 100\n",
    "facility_effect <- ifelse(facility_types == 'Hospital', 100,\n",
    "                         ifelse(facility_types == 'Health Center', 50, 0))\n",
    "day_of_year <- as.numeric(format(dates, '%j'))\n",
    "seasonal_effect <- 20 * sin(2 * pi * day_of_year / 365)\n",
    "noise <- rnorm(n_rows, 0, 15)\n",
    "\n",
    "demand <- pmax(base_demand + facility_effect + seasonal_effect + noise, 10)\n",
    "\n",
    "df <- tibble(\n",
    "  date = dates,\n",
    "  region = factor(regions),\n",
    "  facility_type = factor(facility_types),\n",
    "  demand = as.integer(demand)\n",
    ")\n",
    "\n",
    "cat(\"Data shape:\", nrow(df), \"rows x\", ncol(df), \"columns\\n\")\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "df <- df %>%\n",
    "  mutate(\n",
    "    month = month(date),\n",
    "    day_of_week = wday(date),\n",
    "    quarter = quarter(date),\n",
    "    day_of_year = yday(date)\n",
    "  )\n",
    "\n",
    "cat(\"Features created:\\n\")\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recipe for preprocessing\n",
    "# In tidymodels, we use recipes to handle feature engineering\n",
    "\n",
    "demand_recipe <- recipe(demand ~ region + facility_type + month + day_of_week + quarter, \n",
    "                       data = df) %>%\n",
    "  # Convert categorical to dummy variables (needed for linear regression)\n",
    "  step_dummy(all_nominal_predictors())\n",
    "\n",
    "cat(\"Recipe defined with features: region, facility_type, month, day_of_week, quarter\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "set.seed(42)\n",
    "data_split <- initial_split(df, prop = 0.8)\n",
    "train_data <- training(data_split)\n",
    "test_data <- testing(data_split)\n",
    "\n",
    "cat(\"Training set:\", nrow(train_data), \"samples\\n\")\n",
    "cat(\"Test set:\", nrow(test_data), \"samples\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train Models\n",
    "\n",
    "We'll train three models:\n",
    "1. Linear Regression (baseline)\n",
    "2. Random Forest (using `ranger` engine)\n",
    "3. Gradient Boosting (using `xgboost` engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Linear Regression (Baseline)\n",
    "lr_spec <- linear_reg() %>%\n",
    "  set_engine(\"lm\")\n",
    "\n",
    "lr_workflow <- workflow() %>%\n",
    "  add_recipe(demand_recipe) %>%\n",
    "  add_model(lr_spec)\n",
    "\n",
    "lr_fit <- lr_workflow %>% fit(data = train_data)\n",
    "\n",
    "lr_pred <- predict(lr_fit, test_data) %>%\n",
    "  bind_cols(test_data %>% select(demand))\n",
    "\n",
    "lr_metrics <- lr_pred %>%\n",
    "  metrics(truth = demand, estimate = .pred)\n",
    "\n",
    "lr_rmse <- lr_metrics %>% filter(.metric == \"rmse\") %>% pull(.estimate)\n",
    "lr_rsq <- lr_metrics %>% filter(.metric == \"rsq\") %>% pull(.estimate)\n",
    "\n",
    "cat(\"Linear Regression:\\n\")\n",
    "cat(\"  RMSE:\", round(lr_rmse, 2), \"\\n\")\n",
    "cat(\"  R-squared:\", round(lr_rsq, 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest\n",
    "# Note: Random Forest can handle categorical variables directly (no need for dummies)\n",
    "\n",
    "# Simpler recipe for tree-based models\n",
    "tree_recipe <- recipe(demand ~ region + facility_type + month + day_of_week + quarter, \n",
    "                     data = df)\n",
    "\n",
    "rf_spec <- rand_forest(trees = 100) %>%\n",
    "  set_engine(\"ranger\", importance = \"impurity\") %>%\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "rf_workflow <- workflow() %>%\n",
    "  add_recipe(tree_recipe) %>%\n",
    "  add_model(rf_spec)\n",
    "\n",
    "rf_fit <- rf_workflow %>% fit(data = train_data)\n",
    "\n",
    "rf_pred <- predict(rf_fit, test_data) %>%\n",
    "  bind_cols(test_data %>% select(demand))\n",
    "\n",
    "rf_metrics <- rf_pred %>%\n",
    "  metrics(truth = demand, estimate = .pred)\n",
    "\n",
    "rf_rmse <- rf_metrics %>% filter(.metric == \"rmse\") %>% pull(.estimate)\n",
    "rf_rsq <- rf_metrics %>% filter(.metric == \"rsq\") %>% pull(.estimate)\n",
    "\n",
    "cat(\"Random Forest:\\n\")\n",
    "cat(\"  RMSE:\", round(rf_rmse, 2), \"\\n\")\n",
    "cat(\"  R-squared:\", round(rf_rsq, 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Gradient Boosting (XGBoost)\n",
    "# XGBoost requires numeric encoding\n",
    "\n",
    "xgb_recipe <- recipe(demand ~ region + facility_type + month + day_of_week + quarter, \n",
    "                    data = df) %>%\n",
    "  step_dummy(all_nominal_predictors())\n",
    "\n",
    "gb_spec <- boost_tree(trees = 100) %>%\n",
    "  set_engine(\"xgboost\") %>%\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "gb_workflow <- workflow() %>%\n",
    "  add_recipe(xgb_recipe) %>%\n",
    "  add_model(gb_spec)\n",
    "\n",
    "gb_fit <- gb_workflow %>% fit(data = train_data)\n",
    "\n",
    "gb_pred <- predict(gb_fit, test_data) %>%\n",
    "  bind_cols(test_data %>% select(demand))\n",
    "\n",
    "gb_metrics <- gb_pred %>%\n",
    "  metrics(truth = demand, estimate = .pred)\n",
    "\n",
    "gb_rmse <- gb_metrics %>% filter(.metric == \"rmse\") %>% pull(.estimate)\n",
    "gb_rsq <- gb_metrics %>% filter(.metric == \"rsq\") %>% pull(.estimate)\n",
    "\n",
    "cat(\"Gradient Boosting (XGBoost):\\n\")\n",
    "cat(\"  RMSE:\", round(gb_rmse, 2), \"\\n\")\n",
    "cat(\"  R-squared:\", round(gb_rsq, 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "results <- tibble(\n",
    "  Model = c('Linear Regression', 'Random Forest', 'Gradient Boosting'),\n",
    "  RMSE = round(c(lr_rmse, rf_rmse, gb_rmse), 2),\n",
    "  R_squared = round(c(lr_rsq, rf_rsq, gb_rsq), 3)\n",
    ")\n",
    "\n",
    "cat(\"Model Comparison:\\n\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "all_preds <- bind_rows(\n",
    "  lr_pred %>% mutate(Model = \"Linear Regression\"),\n",
    "  rf_pred %>% mutate(Model = \"Random Forest\"),\n",
    "  gb_pred %>% mutate(Model = \"Gradient Boosting\")\n",
    ")\n",
    "\n",
    "ggplot(all_preds, aes(x = demand, y = .pred)) +\n",
    "  geom_point(alpha = 0.5) +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n",
    "  facet_wrap(~Model) +\n",
    "  labs(\n",
    "    x = \"Actual Demand\",\n",
    "    y = \"Predicted Demand\",\n",
    "    title = \"Predictions vs Actual by Model\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Feature Importance\n",
    "\n",
    "One of the key advantages of tree-based models is interpretability through feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest using vip package\n",
    "rf_fit %>%\n",
    "  extract_fit_parsnip() %>%\n",
    "  vip(num_features = 10) +\n",
    "  labs(title = \"Random Forest Feature Importance\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from XGBoost\n",
    "gb_fit %>%\n",
    "  extract_fit_parsnip() %>%\n",
    "  vip(num_features = 10) +\n",
    "  labs(title = \"XGBoost Feature Importance\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you:\n",
    "- Created features from raw data using `recipe()`\n",
    "- Trained three different ML models using tidymodels `workflow()`\n",
    "- Compared model performance using `metrics()`\n",
    "- Analyzed feature importance using `vip()`\n",
    "\n",
    "### Key tidymodels Functions\n",
    "\n",
    "| Task | Function |\n",
    "|------|----------|\n",
    "| Define preprocessing | `recipe()`, `step_*()` |\n",
    "| Define model | `linear_reg()`, `rand_forest()`, `boost_tree()` |\n",
    "| Combine into workflow | `workflow()`, `add_recipe()`, `add_model()` |\n",
    "| Train model | `fit()` |\n",
    "| Make predictions | `predict()` |\n",
    "| Evaluate | `metrics()`, `rmse()`, `rsq()` |\n",
    "\n",
    "**Next:** Model Tuning notebook to optimize the best performer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

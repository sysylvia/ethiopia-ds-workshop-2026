{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Demand Forecasting with Machine Learning\n",
    "\n",
    "**WISE Workshop | Addis Ababa, Feb 2026**\n",
    "\n",
    "In this notebook, you'll build your first machine learning model to forecast demand in the pharmaceutical supply chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Packages loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data (will be replaced with real data URL)\n",
    "np.random.seed(42)\n",
    "n_rows = 1000\n",
    "\n",
    "# Generate data with patterns\n",
    "dates = pd.date_range('2023-01-01', periods=n_rows, freq='D')\n",
    "regions = np.random.choice(['Addis Ababa', 'Oromia', 'Amhara', 'SNNP', 'Tigray'], n_rows)\n",
    "facility_types = np.random.choice(['Hospital', 'Health Center', 'Clinic'], n_rows, p=[0.2, 0.5, 0.3])\n",
    "\n",
    "# Create demand with seasonal pattern and facility effects\n",
    "base_demand = 100\n",
    "facility_effect = np.where(facility_types == 'Hospital', 100, \n",
    "                          np.where(facility_types == 'Health Center', 50, 0))\n",
    "seasonal_effect = 20 * np.sin(2 * np.pi * dates.dayofyear / 365)\n",
    "noise = np.random.normal(0, 15, n_rows)\n",
    "\n",
    "demand = base_demand + facility_effect + seasonal_effect + noise\n",
    "demand = np.maximum(demand, 10)  # Ensure positive\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'region': regions,\n",
    "    'facility_type': facility_types,\n",
    "    'demand': demand.astype(int)\n",
    "})\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Encode categorical variables\n",
    "le_region = LabelEncoder()\n",
    "le_facility = LabelEncoder()\n",
    "\n",
    "df['region_encoded'] = le_region.fit_transform(df['region'])\n",
    "df['facility_encoded'] = le_facility.fit_transform(df['facility_type'])\n",
    "\n",
    "print(\"Features created:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_cols = ['month', 'day_of_week', 'quarter', 'region_encoded', 'facility_encoded']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['demand']\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Linear Regression (Baseline)\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"  RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"  R²: {lr_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"  RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"  R²: {rf_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "gb_r2 = r2_score(y_test, gb_pred)\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"  RMSE: {gb_rmse:.2f}\")\n",
    "print(f\"  R²: {gb_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'RMSE': [lr_rmse, rf_rmse, gb_rmse],\n",
    "    'R²': [lr_r2, rf_r2, gb_r2]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, pred, name in zip(axes, [lr_pred, rf_pred, gb_pred], \n",
    "                          ['Linear Regression', 'Random Forest', 'Gradient Boosting']):\n",
    "    ax.scatter(y_test, pred, alpha=0.5)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Demand')\n",
    "    ax.set_ylabel('Predicted Demand')\n",
    "    ax.set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(data=importance, x='importance', y='feature', ax=ax)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title('Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you:\n",
    "- Created features from raw data\n",
    "- Trained three different ML models\n",
    "- Compared model performance\n",
    "- Analyzed feature importance\n",
    "\n",
    "**Next:** Model Tuning notebook to optimize the best performer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

---
title: "Fundamentals of Data Science"
subtitle: "Day 1 | WISE Workshop — Addis Ababa 2026"
author: "Sean Sylvia, Ph.D."
date: 2026-02-02
date-format: long
format:
  revealjs:
    theme: [default, ../style/workshop.scss]
    slide-number: true
    chalkboard: true
    transition: fade
    progress: true
    incremental: false
    center: true
    scrollable: true
    smaller: true
    footer: "WISE Workshop | Data Sciences for Modeling & HTA"
    toc: true
    toc-depth: 1
---

# Learning Objectives {.center}

## By the End of This Session, You Will...

1. **Distinguish** between statistics, econometrics, and machine learning approaches
2. **Identify** when prediction vs. causal inference is the right goal
3. **Understand** how ML fits into the workshop's overall pipeline
4. **Articulate** prediction challenges in your own supply chain context

::: notes
This session is about framing — "why" and "when" rather than "how."
The technical "how" comes in Days 2-3.
Connect this to their actual work throughout.
:::

# The Data Revolution in Health {.center}

## A Transformative Moment

Health systems across Africa are experiencing an unprecedented data explosion.

::: fragment
:::: {.columns}
::: {.column width="50%"}
### What's Changing
- Electronic inventory systems
- Digital health records
- Mobile health platforms
- Real-time reporting
:::

::: {.column width="50%"}
### The Opportunity
- Earlier detection of problems
- More efficient resource allocation
- Evidence-based policy decisions
- Improved health outcomes
:::
::::
:::

::: fragment
> **Discussion:** What data sources does your organization currently use? What challenges do you face?
:::

::: notes
This is an opening discussion moment — give 2-3 minutes for informal sharing.
Note down examples they mention for later reference.
:::

---

## AI as Economic Transformation 

### Economics of Digitization: 

**Reduction in (Marginal) Costs **

| Cost Type | Healthcare Application |
|---------------|----------------------------|
| **Search Costs** | Instant medical literature access, symptom lookup |
| **Replication Costs** | Digital health records, AI models deployed at scale |
| **Transportation Costs** | Telemedicine, remote monitoring, digital consultations |
| **Tracking Costs** | Continuous patient surveillance, automated data collection |
| **Verification Costs** | Digital identity, online reputation systems, trust mechanisms |

---

## The Dream: AI-Enabled Healthcare

:::: {.columns}

::: {.column width="50%"}
### What AI Can Do

- Extend specialist expertise to frontline workers
- Standardize care quality across settings
- Enable continuous learning from practice
- Reduce diagnostic delays
:::

::: {.column width="50%"}
### The Sustainability Question

- Can AI systems improve **and** remain equitable over time?
- Will they work for **hard-to-reach** populations?
- How do we design for **long-term** rather than short-term gains?
:::

::::

---

## The Leapfrog Opportunity {.center} {.smaller}

:::: {.columns}

::: {.column width="60%"}
![](/images/adri-v2-leapfrog-final.jpg){fig-align="center" width="100%"}
:::

::: {.column width="40%"}

::: {.fragment}
### The Choice LMICs Face

**Option 1: Follow the HIC Path**

- Safe, proven trajectory
- Limited by legacy infrastructure
- Ceiling set by institutional debt
:::

::: {.fragment}
**Option 2: Leapfrog to the Frontier**

- Skip legacy systems entirely
- Higher potential productivity
- **But significant uncertainty**

### The Question
How do we capture the leapfrog opportunity while managing the risk?

:::

:::

::::

::: {.notes}
[~45 sec] Open with opportunity, not problems. LMICs have a unique chance to skip the mistakes of HIC health IT. Mobile penetration is high, CHW networks exist—the infrastructure is there. But leapfrogging comes with uncertainty. The question is: how do we design systems that capture this opportunity while managing the risk?
:::

---

## AI is Different {.center}

![](/images/adri-v2-sociotechnical-loop.svg){fig-align="center" width="90%"}

:::: {.columns}

::: {.column width="50%"}

#### The Complexity {style="font-size: 0.85em;"}

- Data shapes decisions → decisions change behaviors
- Behaviors generate new data → **feedback loops**
- Yesterday's patterns ≠ tomorrow's reality
- **Unknown unknowns** we can't predict upfront

:::

::: {.column width="50%"}

#### The Core Insight {style="font-size: 0.85em;"}

Health systems are **information-processing and decision-making factories**.

Digital systems transform the factory floor—not just *how* care is delivered, but *what* care, *when*, and to *whom*.

:::

::::

::: {.callout-note appearance="minimal" style="max-width: 900px; margin: 0.5em auto; text-align: center;"}
We must **learn about the system** before deploying—and **design to learn** continuously after.
:::

::: {.notes}
[~90 sec] Health systems are fundamentally information-processing machines. Digital health doesn't just make processes faster—it changes what decisions get made, when, and for whom.

But here's the complexity: these are sociotechnical systems with feedback loops. Data shapes decisions, decisions change behaviors, and those changed behaviors generate new data. The system you're trying to improve keeps shifting under your feet.

This means unknown unknowns—emergent effects we can't predict upfront. You can't retrofit sustainability onto a digital health system after deployment. The sociotechnical has to be designed in from the start. We need to learn about the system before deploying, and design systems that continue learning after.
:::

---

## AI Often Fails In Healthcare 

| System | Scope | Key Failure | Real-World Impact |
|--------|-------|-------------|-------------------|
| **Epic Sepsis Model** | 56% of US hospitals | Missed 67% of cases, false alerts 88% of the time | Delayed treatment, alert fatigue |
| **IBM Watson Oncology** | Major hospitals globally | Unsafe treatment recommendations | $62M+ wasted, quietly discontinued |
| **SkinVision App** | Consumer market | 235% worse performance with rotation | Missed melanomas, health disparities |
| **COMPAS (Criminal Justice)** | 46 US states | 44.9% vs 23.5% false positive rates | Systematic racial bias in sentencing |

::: {.fragment}
**Pattern:** Technical validation ≠ Real-world success
:::

::: {.notes}
Each row represents millions in investment and thousands of lives affected. The pattern is clear: systems that pass technical validation fail when deployed in complex social systems. Include source citations in appendix.
:::

---

## Six Challenges to AI Adoption 

![](/images/six-challenges.png){width="100%"}

---

## ECAM: Four Principles for Sustainable AI {.center data-background-color="#13294B"}

::: {style="color: white;"}

:::: {.columns}

::: {.column width="20%"}
![](/images/adri-v2-ecam-cycle.svg){fig-align="center" width="100%"}
:::

::: {.column width="20%"}
### **E**NGAGE
Stakeholders First

- Map stakeholders **before** building
- CHWs, patients, officials
- Co-design, not consultation
:::

::: {.column width="20%"}
### **C**ALIBRATE
Local Context

- Train on local populations
- Local languages, diseases
- Don't import HIC models
:::

::: {.column width="20%"}
### **A**UDIT
Bias Continuously

- Equity audits by subgroup
- Gender, geography, SES
- Check for hallucination
:::

::: {.column width="20%"}
### **M**ONITOR
Adapt Continuously

- Human override mechanisms
- Retraining triggers
- Performance dashboards
:::

::::

::: {style="text-align: center; font-size: 0.6em; margin-top: 1.5em; opacity: 0.8;"}
Templin et al. (2024) [PLOS Digital Health](https://doi.org/10.1371/journal.pdig.0000474) | Templin et al. (2025) [npj Digital Medicine](https://doi.org/10.1038/s41746-024-01350-x)
:::

:::

::: {.notes}
[~120 sec] Based on our work synthesizing challenges and evaluation frameworks for AI in healthcare, we propose four principles—ECAM.

**Engage:** Before you write a line of code, map your stakeholders. Community health workers, patients, local officials. Co-design, not just consultation.

**Calibrate:** Don't import models trained on US or European populations. Calibrate to local languages, disease patterns, care pathways.

**Audit:** Build in equity audits from day one. Test across subgroups—gender, geography, socioeconomic status. Check for hallucination.

**Monitor:** Design for feedback. Human override mechanisms. Continuous retraining triggers. Performance dashboards.
:::

---

# What Is Data Science? {.center}

## The Intersection of Three Fields

![Data science sits at the intersection of domain knowledge, statistics, and computing](../images/data-science-venn.png){fig-alt="Venn diagram showing data science as the intersection of domain knowledge (health systems, supply chains, policy), statistics and math (probability, inference, modeling), and computing (programming, data management, visualization)" width="85%"}

::: fragment
**Your domain expertise is essential** — algorithms alone cannot solve health system challenges.
:::

::: notes
Emphasize that participants bring the domain expertise.
We're providing methods, but their knowledge makes it meaningful.
:::

# The Fundamental Question {.center}

## Can We Predict Health Outcomes Accurately?

This is the core question that motivates modern data science in health.

::: fragment
:::: {.columns}
::: {.column width="50%"}
### Traditional Statistics
- Focus on **inference** ($\hat{\beta}$)
- Understanding relationships
- Hypothesis testing
- Causal interpretation
:::

::: {.column width="50%"}
### Machine Learning
- Focus on **prediction** ($\hat{y}$)
- Minimizing forecast error
- Out-of-sample performance
- Pattern recognition
:::
::::
:::

::: fragment
> Both approaches are valuable — the key is knowing **when to use each**.
:::

::: notes
This is THE key distinction for the workshop.
Beta-hat = we care about the coefficient (causation).
Y-hat = we care about the prediction (forecasting).
:::

## Supply Chain Prediction Tasks

How can prediction improve pharmaceutical supply chains?

| Task | Traditional Approach | ML Approach | Benefit |
|------|---------------------|-------------|---------|
| **Demand Forecasting** | ARIMA, exponential smoothing | Random forests, gradient boosting | Captures complex patterns |
| **Stockout Risk** | Threshold rules | Ensemble classification | Earlier warning |
| **Lead Time Estimation** | Average + buffer | ML with facility features | Facility-specific estimates |
| **Expiry Prediction** | Simple ratios | Pattern learning | Waste reduction |

: {.striped .hover}

::: notes
These are concrete examples they'll work with in Days 2-3.
Ask which of these resonate with their work.
:::

# Ethiopia's Pharmaceutical Supply Chain {.center}

## The Context

:::: {.columns}
::: {.column width="50%"}
### Scale & Complexity
- **EPSA** manages distribution nationwide
- **3,500+** health facilities served
- **1,000+** essential medicines tracked
- Multiple distribution tiers
:::

::: {.column width="50%"}
### Key Challenges
- Medication stockouts
- Demand variability
- Transportation constraints
- Information gaps
:::
::::

::: notes
This is their context — make sure examples throughout connect back here.
The WISE project is specifically about building Ethiopian capacity.
:::

# Three Paradigms of Quantitative Analysis {.center}

## Statistics, Econometrics, and Machine Learning

| Approach | Primary Goal | Key Question |
|----------|--------------|--------------|
| **Statistics** | Estimation & inference | "What is the relationship?" |
| **Econometrics** | Causal identification | "What is the effect?" |
| **Machine Learning** | Prediction | "What will happen next?" |

: {.striped}

::: fragment
### The "Beta-Hard" vs "Y-Hard" Distinction

- **Beta-hard tasks**: We care about *why* — causal or structural inference
- **Y-hard tasks**: We care about *what* — accurate prediction is the goal
:::

::: notes
This terminology comes from the economics/ML literature.
Beta-hard = hard to estimate the causal parameter.
Y-hard = hard to predict the outcome accurately.
:::

## When to Use Each Approach

| Scenario | Best Approach | Example |
|----------|---------------|---------|
| Testing if an intervention works | **Econometrics** | Does the new distribution policy reduce stockouts? |
| Understanding which factors matter | **Statistics** | Which facility characteristics correlate with stockouts? |
| Forecasting next month's demand | **ML** | How much of Drug X should we deliver to Region Y? |
| Optimizing resource allocation | **ML** | Which facilities are highest risk for stockouts? |

: {.striped .hover}

::: fragment
> In practice, we often combine approaches — this workshop shows you how.
:::

# The Prediction-Simulation Connection {.center}

## How This Workshop Fits Together

![The workshop pipeline: from data through ML models and simulation to policy insights](../images/workshop-pipeline.png){fig-alt="Flowchart showing workshop pipeline: Historical Data (facility reports, inventory levels, demand patterns) flows to ML Models (demand forecasting, risk prediction, Days 2-3) flows to Agent-Based Model (supply chain simulation, policy scenarios, Days 3-4) flows to Policy Insights (optimal allocation, intervention design, evidence for decisions)" width="850"}

::: fragment
**ML predictions feed simulation models** — enabling "what if" policy analysis.
:::

::: notes
This is the workshop's organizing framework.
Data → ML → ABM → Policy.
Each day builds toward this pipeline.
:::

# ML Is About Prediction {.center}

## An Important Clarification

::: {.callout-note}
### Important!

Machine Learning is about prediction. **Period.**

It does not magically solve the causal inference problem.

**What ML CAN do:**

1. Provide accurate forecasts for planning and allocation
2. Identify high-risk facilities or products for intervention
3. Help strengthen causal analyses in specific ways (we'll see this later)

**What ML CANNOT do:**

- Tell you *why* something happens
- Prove that changing X will cause Y to change
- Replace careful study design for causal questions
:::

::: notes
This is a key takeaway to prevent misuse of ML.
Many people think ML = magic causal machine. It's not.
:::

## A Concrete Example: Poverty Targeting

:::: {.columns}
::: {.column width="50%"}
### The Task
Governments need to identify poor households for social assistance programs.

**Traditional approach:** Survey everyone (expensive, slow)

**ML approach:** Predict consumption from observable characteristics
:::

::: {.column width="50%"}
### How It Works
1. Survey a sample of households
2. Train ML model: characteristics → consumption
3. Apply model to rank all households
4. Target resources to highest-need predictions

**Result:** Same budget reaches more people in need
:::
::::

::: fragment
> **Key insight:** This is purely *predictive* — the model doesn't explain *why* households are poor, but it identifies *who* is poor.
:::

::: notes
This is a real-world example from development economics.
Similar logic applies to supply chain: predict which facilities will stock out.
We don't need to know why to allocate resources effectively.
:::

# What This Workshop Will Build {.center}

## Day-by-Day Preview

| Day | Focus | What You'll Learn |
|-----|-------|-------------------|
| **Day 1** | Foundations | Reproducible research, project setup |
| **Day 2** | ML Pipeline | Forecasting models, evaluation methods |
| **Day 3** | Integration | Connecting ML outputs to simulation |
| **Day 4** | ABM Deep Dive | Agent-based modeling for policy |

: {.striped}

::: fragment
By the end: You'll have built a complete pipeline from data to policy-relevant predictions.
:::

# The Data Science Mindset {.center}

## Five Principles for This Week

::: {.nonincremental}
1. **Prediction is not causation** — Always ask "what question am I answering?"

2. **Out-of-sample performance matters** — Models that memorize data are useless

3. **Domain expertise is essential** — Algorithms can't replace your knowledge

4. **Reproducibility is non-negotiable** — Code and documentation matter

5. **Perfect is the enemy of good** — A useful model today beats a perfect model never
:::

::: notes
These five principles should guide their thinking throughout.
Return to these when they face decisions about methods.
:::

# Your Role This Week {.center}

## Bringing Your Expertise

:::: {.columns}
::: {.column width="50%"}
### What You Bring
- Understanding of your health system
- Knowledge of supply chain realities
- Awareness of data quality issues
- Ideas for relevant applications
:::

::: {.column width="50%"}
### What We'll Provide
- Technical methods and tools
- Hands-on practice opportunities
- Templates and code examples
- Frameworks for thinking about problems
:::
::::

::: fragment
**The best outcomes come from combining both** — methods without context are just math.
:::

# Discussion: Your Supply Chain Challenges {.center}

## Let's Hear From You

In small groups (3-4 people), discuss:

::: fragment
1. **What prediction problems** do you face in your work?
   - What would you want to forecast more accurately?
:::

::: fragment
2. **What data exists** that could help?
   - What's available? What's missing?
:::

::: fragment
3. **What decisions** would better predictions improve?
   - How would you use the predictions?
:::

::: fragment
**Time:** 5-7 minutes in groups, then brief sharing
:::

::: notes
Circulate during small group discussion.
Take notes on challenges mentioned — these can inform examples later.
Have 2-3 groups share briefly with full room.
:::

# Key Takeaways {.center}

## Remember This

::: {.callout-warning}
### Prediction vs. Causation

**What ML gives you:**

- Accurate predictions ($\hat{y}$)
- Pattern recognition
- Risk stratification

**What ML does NOT give you:**

- Causal effects ($\hat{\beta}$)
- Mechanism understanding
- Policy counterfactuals
:::

> For "Why?" questions, we need careful study design. For "What's next?" questions, ML is powerful.

# What's Next {.center}

## Rest of Today's Schedule

| Time | Session | Description |
|------|---------|-------------|
| 10:30-10:50 | *Break* | |
| 10:50-12:30 | Data Science in Public Health Policy | Ozawa |
| 12:30-1:30 | *Lunch* | |
| 1:30-3:00 | ML Foundations: Core Concepts | Sylvia |
| 3:00-3:20 | *Break* | |
| 3:20-5:00 | Hands-on: Setup + ML Demo | Sylvia |

: {.striped}

::: fragment
**Afternoon hands-on:** We'll set up everything you need for the rest of the week.
:::

# Questions? {.center}

## Before We Continue

:::: {.columns}
::: {.column width="50%"}
### About Concepts
- ML vs. statistics
- When prediction matters
- Workshop structure
:::

::: {.column width="50%"}
### About Practice
- Technical requirements
- What we'll build
- How to prepare
:::
::::

::: fragment
> No question is too basic — we're all learning together.
:::
